<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    

    

    



    <meta charset="utf-8">
    
    <meta name="google-site-verification" content="true">
    
    
    
    
    <title>Hive on Spark 搭建 | Pengyun&#39;s Blog | ლ(ٱ٥ٱლ)</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Hive,Spark">
    <meta name="description" content="Hive on Spark 就是把 Hive 默认的执行引擎从 MapReduce 换成 Apache Spark。Hive on Spark 只在 Spark 的制定版本上进行了测试，其它版本则不是很有保证。对稳定性有要求可以去官方文档查看版本兼容性，再根据 Hive 和 Spark 源码中 pom 文件的配置，另行选择版本。这里几乎全部选择最新版进行演示。 环境及一些信息 VMWare 15，">
<meta name="keywords" content="Hive,Spark">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive on Spark 搭建">
<meta property="og:url" content="https://pyun.top/2019/running-hive-on-spark/index.html">
<meta property="og:site_name" content="Pengyun&#39;s Blog">
<meta property="og:description" content="Hive on Spark 就是把 Hive 默认的执行引擎从 MapReduce 换成 Apache Spark。Hive on Spark 只在 Spark 的制定版本上进行了测试，其它版本则不是很有保证。对稳定性有要求可以去官方文档查看版本兼容性，再根据 Hive 和 Spark 源码中 pom 文件的配置，另行选择版本。这里几乎全部选择最新版进行演示。 环境及一些信息 VMWare 15，">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-06-10T14:46:17.245Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive on Spark 搭建">
<meta name="twitter:description" content="Hive on Spark 就是把 Hive 默认的执行引擎从 MapReduce 换成 Apache Spark。Hive on Spark 只在 Spark 的制定版本上进行了测试，其它版本则不是很有保证。对稳定性有要求可以去官方文档查看版本兼容性，再根据 Hive 和 Spark 源码中 pom 文件的配置，另行选择版本。这里几乎全部选择最新版进行演示。 环境及一些信息 VMWare 15，">
    
        <link rel="alternate" type="application/atom+xml" title="Pengyun&#39;s Blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide">
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">pengyun</h5>
          <a href="mailto:koaidw@163.com" title="koaidw@163.com" class="mail">koaidw@163.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/">
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives/">
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags/">
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Hive on Spark 搭建</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Hive on Spark 搭建</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-06-10T13:59:43.000Z" itemprop="datePublished" class="page-time">
  2019-06-10
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#环境及一些信息"><span class="post-toc-number">1.</span> <span class="post-toc-text">环境及一些信息</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#准备"><span class="post-toc-number">2.</span> <span class="post-toc-text">准备</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#安装"><span class="post-toc-number">3.</span> <span class="post-toc-text">安装</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Java、Maven-和-Scala-安装"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">Java、Maven 和 Scala 安装</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Hadoop-安装"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">Hadoop 安装</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Spark-安装"><span class="post-toc-number">3.3.</span> <span class="post-toc-text">Spark 安装</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Hive-安装"><span class="post-toc-number">3.4.</span> <span class="post-toc-text">Hive 安装</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#运行"><span class="post-toc-number">4.</span> <span class="post-toc-text">运行</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Spark"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">Spark</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Hive"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">Hive</span></a></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-hive-on-spark-deploy" class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Hive on Spark 搭建</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-06-10 21:59:43" datetime="2019-06-10T13:59:43.000Z" itemprop="datePublished">2019-06-10</time>

            


            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style="display:none">
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <p>Hive on Spark 就是把 Hive 默认的执行引擎从 MapReduce 换成 Apache Spark。<br>Hive on Spark 只在 Spark 的制定版本上进行了测试，其它版本则不是很有保证。对稳定性有要求可以去<a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started" target="_blank" rel="noopener">官方文档</a>查看版本兼容性，再根据 Hive 和 Spark 源码中 pom 文件的配置，另行选择版本。这里几乎全部选择最新版进行演示。</p>
<h2 id="环境及一些信息"><a href="#环境及一些信息" class="headerlink" title="环境及一些信息"></a>环境及一些信息</h2><ul>
<li>VMWare 15，参考之前的<a href="https://pyun.top/2019/setup-docker-develop-environment-based-on-vmware/">搭建博文</a><ul>
<li>Ubuntu 18.04 bionic</li>
<li>8G 内存</li>
<li>Docker 18.09.0</li>
<li>IP: 192.168.99.100，后面看到这个地址出现就自行翻译成你们运行环境的ip</li>
<li>全程 root 用户操作（手动滑稽）</li>
</ul>
</li>
</ul>
<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ol>
<li><a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/" target="_blank" rel="noopener">安装Docker</a>，拉取 <a href="https://hub.docker.com/_/mysql" target="_blank" rel="noopener">MySQL 8</a> 镜像（不使用 Docker 的后面自行安装 MySQL）</li>
<li>下载安装包<ul>
<li><a href="https://github.com/AdoptOpenJDK/openjdk8-binaries/releases/download/jdk8u212-b04/OpenJDK8U-jdk_x64_linux_hotspot_8u212b04.tar.gz" target="_blank" rel="noopener">AdoptOpenJDK 8</a></li>
<li><a href="https://www-eu.apache.org/dist/maven/maven-3/3.6.1/binaries/apache-maven-3.6.1-bin.tar.gz" target="_blank" rel="noopener">Maven 3.6.1</a></li>
<li><a href="http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz" target="_blank" rel="noopener">Hadoop 3.1.2</a></li>
<li><a href="https://www-eu.apache.org/dist/hive/hive-3.1.1/apache-hive-3.1.1-bin.tar.gz" target="_blank" rel="noopener">Hive 3.1.1</a></li>
<li><a href="https://downloads.lightbend.com/scala/2.11.12/scala-2.11.12.tgz" target="_blank" rel="noopener">Scala 2.11.12</a></li>
<li><a href="http://ftp.ntu.edu.tw/MySQL/Downloads/Connector-J/mysql-connector-java-8.0.16.tar.gz" target="_blank" rel="noopener">Mysql Connector 8.0.16</a></li>
</ul>
</li>
<li><p>Spark 二进制包可以在<a href="https://archive.apache.org/dist/spark/" target="_blank" rel="noopener">这里</a>获取，但是我们要自己编译不内建 Hive 的版本，所以要下载源码编译</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone -b v2.3.3 https://github.com/apache/spark.git</span><br><span class="line">rm -rf spark/.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建 /home/tools 文件夹，将解压后的安装包和源码都放这里，解压后的 <code>mysql-connector-java-8.0.16.jar</code> 放到 <code>/home/tools/hive/lib</code></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">home  </span><br><span class="line">| -- tools  </span><br><span class="line">     | -- hadoop  </span><br><span class="line">     | -- hive  </span><br><span class="line">          | -- lib</span><br><span class="line">               | -- mysql-connector-java-8.0.16.jar</span><br><span class="line">     | -- java   </span><br><span class="line">     | -- maven</span><br><span class="line">     | -- scala  </span><br><span class="line">     | -- spark-source</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="Java、Maven-和-Scala-安装"><a href="#Java、Maven-和-Scala-安装" class="headerlink" title="Java、Maven 和 Scala 安装"></a>Java、Maven 和 Scala 安装</h3><ul>
<li><p>编辑 <code>/etc/profile</code>，加入环境变量  </p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/home/tools/java</span><br><span class="line">export M2_HOME=/home/tools/maven</span><br><span class="line">export SCALA_HOME=/home/tools/scala</span><br><span class="line">export PATH=$&#123;M2_HOME&#125;/bin:$&#123;SCALA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/bin:$PATH</span><br></pre></td></tr></table></figure>
</li>
<li><p>在终端运行以下指令，若显示出 jdk、Scala 和 Maven 版本，则安装已完成</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br><span class="line">java -version</span><br><span class="line">scala -version</span><br><span class="line">mvn -v</span><br></pre></td></tr></table></figure>
</li>
<li><p>（可选）网络不好的孩纸可自行配置 Maven 的仓库为阿里云的镜像</p>
<h3 id="Hadoop-安装"><a href="#Hadoop-安装" class="headerlink" title="Hadoop 安装"></a>Hadoop 安装</h3></li>
<li><p>安装需要的软件</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install -y ssh pdsh rsync</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置</p>
<ul>
<li><p><code>etc/hadoop/core-site.xml</code>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        name&gt;fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/tmp/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>etc/hadoop/hdfs-site.xml</code>:  </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>etc/hadoop/mapred-site.xml</code>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>etc/hadoop/yarn-site.xml</code>:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><code>sbin/start-dfs.sh</code>、<code>sbin/stop-dfs.sh</code> 头部配置使用 root 账户:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line">HDFS_DATANODE_USER=root</span><br><span class="line">HDFS_DATANODE_SECURE_USER=hdfs</span><br><span class="line">HDFS_NAMENODE_USER=root</span><br><span class="line">HDFS_SECONDARYNAMENODE_USER=root</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>sbin/start-yarn.sh</code>、<code>sbin/stop-yarn.sh</code> 头部配置使用 root 账户:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line">YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=yarn</span><br><span class="line">YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>etc/hadoop/hadoop-env.sh</code> 中添加:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PDSH_RCMD_TYPE=ssh</span><br><span class="line">export JAVA_HOME=/home/tools/java</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>配置 SSH 密钥登录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -P <span class="string">''</span> -f ~/.ssh/id_rsa</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">chmod 0600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>
<p>修改 SSH 配置文件 <code>/etc/ssh/sshd_config</code>，加入:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PermitRootLogin yes       </span><br><span class="line">PubkeyAuthentication yes</span><br></pre></td></tr></table></figure>
<p>重启 SSH 服务:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ssh restart</span><br></pre></td></tr></table></figure>
<p>运行 <code>ssh localhost</code> 测试，看是否直接登录到本机</p>
</li>
<li><p>格式化文件系统</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行 HDFS，运行成功后可访问 <a href="http://192.168.99.100:9870" target="_blank" rel="noopener">http://192.168.99.100:9870</a> 查看 NameNode 的 Web 管理界面</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行 yarn，运行成功后可访问 <a href="http://192.168.99.100:8088" target="_blank" rel="noopener">http://192.168.99.100:8088</a> 查看 ResourceManager 的 Web 管理界面</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Spark-安装"><a href="#Spark-安装" class="headerlink" title="Spark 安装"></a>Spark 安装</h3><ul>
<li><p>编译不带 Hive 的版本</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/tools/spark-source</span><br><span class="line">./dev/make-distribution.sh --name <span class="string">"hadoop3-without-hive"</span> --tgz <span class="string">"-Pyarn,-Phadoop-3.1,-Dhadoop.version=3.1.2,parquet-provided,orc-provided"</span></span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line">mkdir spark</span><br><span class="line">tar -xf spark-source/spark-2.3.3-bin-hadoop3-without-hive.tgz --strip-components 1 -C spark</span><br></pre></td></tr></table></figure>
</li>
<li><p>新建配置文件 <code>/home/tools/spark/conf/spark-env.sh</code>:</p>
  <figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/home/tools/java</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/home/tools/hadoop/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> SPARK_DIST_CLASSPATH=$(/home/tools/hadoop/bin/hadoop classpath)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="Hive-安装"><a href="#Hive-安装" class="headerlink" title="Hive 安装"></a>Hive 安装</h3><ul>
<li><p>复制 Jar 包到 Hive 的 <code>lib</code> 文件夹，其中某些包的小版本号可能会不一样</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/tools/hive</span><br><span class="line">cp ../scala/lib/scala-library.jar lib/</span><br><span class="line">cp ../spark/jars/spark-core_2.11-2.3.3.jar lib/</span><br><span class="line">cp ../spark/jars/spark-network-common_2.11-2.3.3.jar lib/</span><br><span class="line">cp ../spark/jars/jersey-container-servlet-core-2.22.2.jar lib/</span><br><span class="line">cp ../spark/jars/jersey-server-2.22.2.jar lib/</span><br><span class="line">cp ../spark/jars/json4s-ast_2.11-3.2.11.jar lib/</span><br><span class="line">cp ../spark/jars/kryo-shaded-3.0.3.jar lib/</span><br><span class="line">cp ../spark/jars/minlog-1.3.0.jar lib/</span><br><span class="line">cp ../spark/jars/scala-xml_2.11-1.0.5.jar lib/</span><br><span class="line">cp ../spark/jars/spark-launcher_2.11-2.3.3.jar lib/</span><br><span class="line">cp ../spark/jars/spark-network-shuffle_2.11-2.3.3.jar lib/</span><br><span class="line">cp ../spark/jars/spark-unsafe_2.11-2.3.3.jar lib/</span><br><span class="line">cp ../spark/jars/xbean-asm5-shaded-4.4.jar lib/</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置 <code>conf/hive-site.yml</code>，并复制到 $SPARK_HOME/conf:</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:21109/metastore?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.cj.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>123123<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.execution.engine<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>spark<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.enable.spark.execution.engine<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark.yarn.jars<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000/spark-jars/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark.master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>spark://localhost.localdomain:7077<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark.eventLog.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark.eventLog.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///home/tools/hive/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span> #</span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark.serializer<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.spark.serializer.KryoSerializer<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>创建运行数据库实例的 <code>docker-compose.yml</code> :</p>
  <figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"2.4"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">mysql:</span></span><br><span class="line"><span class="attr">    restart:</span> <span class="string">always</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">mysql:8</span></span><br><span class="line"><span class="attr">    container_name:</span> <span class="string">mysql4hive</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="number">21109</span><span class="string">:3306</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="attr">      MYSQL_ROOT_PASSWORD:</span> <span class="number">123123</span></span><br></pre></td></tr></table></figure>
<p>在 <code>docker-compose.yml</code> 所在目录运行:</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化数据库，提示 schemaTool completed 则为成功，连接数据库实例，能看到 <code>metastore</code> 数据库和相关的表 </p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/tools/hive/bin/schematool -initSchema -dbType mysql</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改 <code>/etc/profile</code> 配置环境变量</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/home/tools/hive</span><br><span class="line">export SPARK_HOME=/home/tools/spark</span><br><span class="line">export HADOOP_HOME=/home/tools/hadoop</span><br><span class="line">export PATH=$HIVE_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加文件用来插入假数据 <code>test_data.txt</code>:</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 Bryant</span><br><span class="line">2 Jordan</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><h3 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/home/tools/spark/sbin/start-all.sh</span><br></pre></td></tr></table></figure>
<h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">root@localhost: /home/tools/hive/bin/beeline -u jdbc:hive2://</span><br><span class="line">hive &gt; create table test2 (id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="string">' '</span>;</span><br><span class="line">hive &gt; load data <span class="built_in">local</span> inpath <span class="string">'/home/tools/hive/test_data.txt'</span> into table test2;</span><br><span class="line">hive &gt; select count(*) from test2;</span><br><span class="line">Hive on Spark Session Web UI URL: http://192.168.99.100:4040</span><br><span class="line"></span><br><span class="line">Query Hive on Spark job[0] stages: [0, 1]</span><br><span class="line">Spark job[0] status = RUNNING</span><br><span class="line">--------------------------------------------------------------------------------------</span><br><span class="line">          STAGES   ATTEMPT        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  </span><br><span class="line">--------------------------------------------------------------------------------------</span><br><span class="line">Stage-0 ........         0      FINISHED      1          1        0        0       0  </span><br><span class="line">Stage-1 ........         0      FINISHED      1          1        0        0       0  </span><br><span class="line">--------------------------------------------------------------------------------------</span><br><span class="line">STAGES: 02/02    [==========================&gt;&gt;] 100%  ELAPSED TIME: 13.05 s    </span><br><span class="line">--------------------------------------------------------------------------------------</span><br><span class="line">Spark job[0] finished successfully <span class="keyword">in</span> 13.05 second(s)</span><br><span class="line">OK</span><br><span class="line">+------+</span><br><span class="line">| _c0  |</span><br><span class="line">+------+</span><br><span class="line">| 2    |</span><br><span class="line">+------+</span><br><span class="line">1 row selected (60.643 seconds)</span><br></pre></td></tr></table></figure>
<p>打完收工 ヾ(￣▽￣)Bye~Bye~</p>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最后更新时间：<time datetime="2019-06-10T14:46:17.245Z" itemprop="dateUpdated">2019-06-10 22:46:17</time>
</span><br>


        
        转载请注明出处：<a href="/2019/running-hive-on-spark/" target="_blank" rel="external">https://pyun.top/2019/running-hive-on-spark/</a>
        
    </div>
    
    <footer>
        <a href="https://pyun.top">
            <img src="/img/avatar.jpg" alt="pengyun">
            pengyun
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/">Hive</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/">Spark</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://pyun.top/2019/running-hive-on-spark/&title=《Hive on Spark 搭建》 — Pengyun's Blog&pic=https://pyun.top/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://pyun.top/2019/running-hive-on-spark/&title=《Hive on Spark 搭建》 — Pengyun's Blog&source=学习的路上，不时写点总结" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://pyun.top/2019/running-hive-on-spark/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Hive on Spark 搭建》 — Pengyun's Blog&url=https://pyun.top/2019/running-hive-on-spark/&via=https://pyun.top" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://pyun.top/2019/running-hive-on-spark/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/jaeger-deploy-with-spring-boot/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Spring Boot + Jaeger 搭建使用</h4>
      </a>
    </div>
  
</nav>



    











    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'false' == 'true',
            verify: 'true' == 'true',
            appId: "w8DAHCKGD4cyHKIhG8e7GPOa-gzGzoHsz",
            appKey: "Ak52XwsQbVkBryeBgCOAMBM6",
            avatar: "robohash",
            placeholder: "Just go go",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->










</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢支持~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wx.png" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check" data-wechat="/img/wx.png" data-alipay="/img/ali.png">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style="display:none">
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style="display:none">
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>博客内容遵循 <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>pengyun &copy; 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://pyun.top/2019/running-hive-on-spark/&title=《Hive on Spark 搭建》 — Pengyun's Blog&pic=https://pyun.top/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://pyun.top/2019/running-hive-on-spark/&title=《Hive on Spark 搭建》 — Pengyun's Blog&source=学习的路上，不时写点总结" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://pyun.top/2019/running-hive-on-spark/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Hive on Spark 搭建》 — Pengyun's Blog&url=https://pyun.top/2019/running-hive-on-spark/&via=https://pyun.top" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://pyun.top/2019/running-hive-on-spark/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACI0lEQVR42u3aQW7DMAwEwP7/0+m1QBFnV3QOlkYnw3EsjQ8ESennJx6vf+Pv/eTJd88k928bGBgYj2W8Lse7CdrJrt9wfX29NgwMjHMY7ya+DqzXE+dRsf1YGBgYGLcFwaWEDwMDA+MbAbf9Vx5kMTAwMNoiNmmW5UVs3s67uRbHwMB4IGOSrn37+iv7GxgYGI9ivMqRFLR3hfJiVRgYGFsz8gCXH7a4DtOLBWqSaGJgYGzKSArR9pDEvKFW38HAwNiakR+DaCvHPMgmLbYCg4GBcQCjbeVPDme07ywCLgYGxnaMtaZY25lfK2Xzj4WBgXEaow2sbRI56g6202BgYDycsbagfEsgD6bJJujb9WBgYBzAWEsK7wJPjqNhYGCcwKizyPIgRd3Wj9t/H9ptGBgYGzGS1G1+tCKvNBcPimFgYBzDyMvOdtsgf8Ni4w8DA+MYxjztyyfOR5SeYmBgHMBoy8t8WVENXZa4RaMNAwNjC0ZbQK4lc3kbblIAY2Bg7M2YpGWTY2Ftovnh02NgYBzGWItjeRMt2dps58LAwDiBkQe7lpEj8xA/2sjEwMB4FGOtTT+5zn8tNkoxMDC2ZuRjbSOzbbdNPgcGBsbejLVScw6eNPKiWhwDA2M7Rrt5mRfDa0fKFktZDAwMjHKJeTMuXy4GBgbGXTXxZJNgLZRjYGCcwEiK2HlDP0/7vliLY2BgPJCRT3Bvi20eZDEwMA5g/AKLmdsZhLHmcgAAAABJRU5ErkJggg==" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>






<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
